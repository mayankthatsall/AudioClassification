{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d18f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68127b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract audio features\n",
    "def extract_features(audio_data):\n",
    "    # Extract Mel-frequency cepstral coefficients (MFCCs)\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=40)\n",
    "    # Calculate the mean and standard deviation of each MFCC coefficient\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    mfccs_std = np.std(mfccs.T, axis=0)\n",
    "    return np.concatenate((mfccs_mean, mfccs_std), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b46fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to audio files\n",
    "data_dir = 'data'\n",
    "classes = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4304536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio files and their corresponding labels\n",
    "X = []\n",
    "y = []\n",
    "label_to_index = {}\n",
    "index_to_label = {}\n",
    "for i, label in enumerate(classes):\n",
    "    label_to_index[label] = i\n",
    "    index_to_label[i] = label\n",
    "    class_path = os.path.join(data_dir, label)\n",
    "    class_files = os.listdir(class_path)\n",
    "    for file_name in class_files:\n",
    "        file_path = os.path.join(class_path, file_name)\n",
    "        audio_data, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        features = extract_features(audio_data)\n",
    "        X.append(features)\n",
    "        y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023f5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c369d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912a86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "split_index = int(len(X) * 0.8) # 80% training, 20% testing\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bfc8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for CNN input\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3edf9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN architecture\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(classes), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aab0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b21be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=len(classes))\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9161d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9610 - val_loss: 0.0139 - val_accuracy: 0.9964\n",
      "Epoch 2/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.1005 - accuracy: 0.9601 - val_loss: 0.0300 - val_accuracy: 0.9946\n",
      "Epoch 3/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.9769 - val_loss: 0.0189 - val_accuracy: 0.9964\n",
      "Epoch 4/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9723 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
      "Epoch 5/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9705 - val_loss: 0.0161 - val_accuracy: 0.9946\n",
      "Epoch 6/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9710 - val_loss: 0.0175 - val_accuracy: 0.9964\n",
      "Epoch 7/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9742 - val_loss: 0.0178 - val_accuracy: 0.9946\n",
      "Epoch 8/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9796 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
      "Epoch 9/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9733 - val_loss: 0.0210 - val_accuracy: 0.9928\n",
      "Epoch 10/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9742 - val_loss: 0.0167 - val_accuracy: 0.9928\n",
      "Epoch 11/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9755 - val_loss: 0.0403 - val_accuracy: 0.9909\n",
      "Epoch 12/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9773 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9742 - val_loss: 0.0105 - val_accuracy: 0.9946\n",
      "Epoch 14/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9778 - val_loss: 0.0120 - val_accuracy: 0.9946\n",
      "Epoch 15/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9764 - val_loss: 0.0180 - val_accuracy: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228ea6ae670>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train_one_hot, batch_size=32, epochs=15, validation_data=(X_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd1f9f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.01797403022646904\n",
      "Test accuracy: 0.9927536249160767\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "score = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "631bf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to working directory\n",
    "model.save('emotion_audio_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a02a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom audio file\n",
    "file_path = 'test_data/neutral/OAF_choice_neutral.wav'\n",
    "audio_data, sr = librosa.load(file_path, res_type='kaiser_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9edb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from audio file\n",
    "features = extract_features(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06e861f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for CNN input\n",
    "features = np.expand_dims(features, axis=0)\n",
    "features = np.expand_dims(features, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8153ccd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make a prediction\n",
    "prediction = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5287fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [1.5699037e-10 5.4681482e-08 2.5704635e-11 5.7200127e-11 1.0000000e+00\n",
      " 5.7933669e-08 6.6398630e-11]\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted class label\n",
    "print('Predicted class:', prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2350cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_class = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Disgust\",\n",
    "    2: \"Fear\",\n",
    "    3: \"Happy\",\n",
    "    4: \"Neutral\",\n",
    "    5: \"Pleasant_Surprised\",\n",
    "    6: \"Sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69621841",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1181fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_name = label_to_class[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d1c7199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted class label\n",
    "print(\"Predicted class label:\", predicted_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1e3198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
